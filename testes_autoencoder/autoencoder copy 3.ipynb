{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentandoDatasets import segmentando_datasets\n",
    "segmentando_datasets(1000,1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras \n",
    "\n",
    "import os\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_strict_conv_algorithm_picker=false'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 13:46:59.585552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-11 13:46:59.599321: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-11 13:46:59.603348: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-11 13:46:59.612993: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 13:47:00.436444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 validated image filenames belonging to 2 classes.\n",
      "Found 200 validated image filenames belonging to 2 classes.\n",
      "Found 200 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from preprocessamento import *\n",
    "\n",
    "csv_file = 'Datasets_csv/df_PUC.csv'\n",
    "treino_gerador, validacao_gerador, teste_gerador, x_treino, y_treino, x_teste, y_teste, x_validacao, y_validacao = preprocessamento(csv_file, 0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_treino.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_shape=(256, 256, 3)):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Definir o encoder\n",
    "        self.encoder = self.build_encoder()\n",
    "        # Definir o decoder\n",
    "        self.decoder = self.build_decoder()\n",
    "\n",
    "    def build_encoder(self):\n",
    "        input_img = Input(shape=self.input_shape)\n",
    "        \n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        \n",
    "        return Model(inputs=input_img, outputs=x, name='encoder')\n",
    "\n",
    "    def build_decoder(self):\n",
    "        input_encoded = Input(shape=self.encoder.output_shape[1:])\n",
    "        \n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "        \n",
    "        return Model(inputs=input_encoded, outputs=decoded, name='decoder')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "autoencoder.build(input_shape=(256, 256, 3)) \n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = 'weights_parciais/weights-improvement-{epoch:02d}-{loss:.2f}.weights.h5'\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                  save_weights_only=True, \n",
    "                                  monitor='loss',\n",
    "                                  mode='max', \n",
    "                                  save_best_only=True, \n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "history = autoencoder.fit(x_treino, x_treino,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                callbacks=[cp_callback],\n",
    "                validation_data=(x_validacao, x_validacao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Modelos_keras/Autoencoder.keras.h5\")\n",
    "autoencoder.save_weights(\"weights_finais/Autoencoder.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(\"weights_finais/Autoencoder.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encode(x_teste)\n",
    "reconstructed_images = autoencoder.decode(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape das imagens de teste:\", x_teste.shape)\n",
    "print(\"Shape das imagens codificadas:\", encoded_imgs.shape)\n",
    "print(\"Shape das imagens reconstruídas:\", reconstructed_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forma das imagens codificadas:\", encoded_imgs.shape)\n",
    "print(\"Forma das labels de treinamento:\", y_treino.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = tf.reshape(encoded_imgs, (encoded_imgs.shape[0], -1))  # Achatar para (batch_size, 32*32*32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_original_and_reconstructed(model, X_val, num_images=5):\n",
    "    \"\"\"\n",
    "    Plota as imagens originais e suas versões reconstruídas pelo autoencoder.\n",
    "    \n",
    "    Parâmetros:\n",
    "        model (keras.Model): O modelo do autoencoder treinado.\n",
    "        X_val (numpy.ndarray): Conjunto de dados de validação.\n",
    "        num_images (int): Número de imagens a serem plotadas.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image_index = np.random.randint(0, len(X_val))\n",
    "        original_image = X_val[image_index]\n",
    "\n",
    "        reconstructed_image = model.predict(original_image.reshape(1, 256, 256, 3))[0]\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(original_image)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(reconstructed_image)\n",
    "        plt.title(\"Reconstruída\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_original_and_reconstructed(autoencoder, x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessamento import preprocessamento_dataframe_unico\n",
    "\n",
    "UFPR04, _ = preprocessamento_dataframe_unico(\"Datasets_csv/df_UFPR04.csv\", True)\n",
    "UFPR05, _ = preprocessamento_dataframe_unico(\"Datasets_csv/df_UFPR05.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_UFPR04,_ = next(UFPR04)\n",
    "X_UFPR05,_ = next(UFPR05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_original_and_reconstructed(autoencoder, X_UFPR04)\n",
    "plot_original_and_reconstructed(autoencoder, X_UFPR05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assumindo que você já tem as imagens codificadas e os rótulos\n",
    "# encoded_imgs shape: (num_amostras, 32, 32, 32)\n",
    "# labels: lista ou array com rótulos 'empty' ou 'occupied'\n",
    "\n",
    "# Converter rótulos para formato numérico\n",
    "label_map = {'empty': 0, 'occupied': 1}\n",
    "numeric_labels = np.array([label_map[label] for label in labels])\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_imgs, numeric_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o modelo\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 32)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Avaliar o modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'\\nAcurácia no conjunto de teste: {test_acc}')\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Você pode usar estas previsões para análise adicional ou visualização"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
