{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Modelos import Gerador\n",
    "import keras.backend as k  \n",
    "import gc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_modelos(n_modelos=10):\n",
    "    for i in range(n_modelos):\n",
    "        k.clear_session()  \n",
    "\n",
    "        Modelo = Gerador(input_shape=(64, 64, 3))\n",
    "        Modelo.setNome(f'Modelo_{i}')\n",
    "        modelo = Modelo.construir_modelo(salvar=True)\n",
    "\n",
    "        modelo.summary()\n",
    "\n",
    "        encoder = Modelo.encoder  \n",
    "        decoder = Modelo.decoder  \n",
    "        encoder.summary()\n",
    "        decoder.summary()\n",
    "\n",
    "        del Modelo, modelo, encoder, decoder\n",
    "        gc.collect()  # Força a coleta de lixo, se necessário\n",
    "\n",
    "cria_modelos(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estrutura de cada um dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Estrutura do Modelo {i}:  \\n\\n\\n\")\n",
    "\n",
    "    Modelo = Gerador()\n",
    "\n",
    "    AutoencoderModelo0 = Modelo.carrega_modelo(f'Modelos_keras/Autoencoders_Gerados/Modelo_{i}.keras')\n",
    "    encoder = Modelo.encoder\n",
    "    decoder = Modelo.decoder \n",
    "\n",
    "\n",
    "    print(\"Encoder:\")\n",
    "    encoder.summary()\n",
    "\n",
    "    print(\"Decoder:\")\n",
    "    decoder.summary()\n",
    "\n",
    "    del Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino, validação e teste - PKLot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessamento import preprocessamento_dataframe\n",
    "\n",
    "treino, treino_df = preprocessamento_dataframe(caminho_csv='PKLot_SegmentadoTreino.csv', autoencoder=True)\n",
    "validacao, validacao_df = preprocessamento_dataframe(caminho_csv='PKLot_SegmentadoValidacao.csv', autoencoder=True)\n",
    "teste, teste_df = preprocessamento_dataframe(caminho_csv='PKLot_SegmentadoTeste.csv', autoencoder=True, data_algumentantation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando cada um dos modelos na PKLot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    Modelo = Gerador()\n",
    "    \n",
    "    print(f\"Treinando o modelo {i}: \")\n",
    "\n",
    "    AutoencoderModelo = Modelo.carrega_modelo(f'Modelos_keras/Autoencoders_Gerados/Modelo_{i}.keras')\n",
    "\n",
    "    Modelo.Dataset(treino, validacao, teste)\n",
    "\n",
    "    Modelo.compilar_modelo()\n",
    "\n",
    "    Modelo.treinar_autoencoder(epocas=30, salvar=True, nome_da_base='PKLot' ,batch_size=8)\n",
    "\n",
    "    del AutoencoderModelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino, validação, teste - CNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessamento import preprocessamento_dataframe\n",
    "\n",
    "treino, treino_df = preprocessamento_dataframe(caminho_csv='CNR_SegmentadoTreino.csv', autoencoder=True)\n",
    "validacao, validacao_df = preprocessamento_dataframe(caminho_csv='CNR_SegmentadoValidacao.csv', autoencoder=True)\n",
    "teste, teste_df = preprocessamento_dataframe(caminho_csv='CNR_SegmentadoTeste.csv', autoencoder=True, data_algumentantation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando cada um dos modelos na CNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Treinando o modelo {i}: \")\n",
    "\n",
    "    Modelo = Gerador()\n",
    "\n",
    "    AutoencoderModelo0 = Modelo.carrega_modelo(f'Modelos_keras/Autoencoders_Gerados/Modelo_{i}.keras')\n",
    "    \n",
    "    Modelo.Dataset(treino, validacao, teste)\n",
    "\n",
    "    Modelo.compilar_modelo()\n",
    "\n",
    "    Modelo.treinar_autoencoder(epocas=30, salvar=True, nome_da_base='CNR', batch_size=8)\n",
    "\n",
    "    del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessamento import preprocessamento_dataframe\n",
    "\n",
    "treino, treino_df = preprocessamento_dataframe(caminho_csv='KyotoTreino.csv', autoencoder=True)\n",
    "validacao, validacao_df = preprocessamento_dataframe(caminho_csv='KyotoValidacao.csv', autoencoder=True)\n",
    "teste, teste_df = preprocessamento_dataframe(caminho_csv='KyotoTeste.csv', autoencoder=True, data_algumentantation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modelo = Gerador()\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Treinando o modelo {i}: \")\n",
    "    AutoencoderModelo = Modelo.carrega_modelo(f'Modelos_keras/Autoencoders_Gerados/Modelo_{i}.keras')\n",
    "\n",
    "    Modelo.Dataset(treino, validacao, teste)\n",
    "\n",
    "    Modelo.compilar_modelo()\n",
    "\n",
    "    Modelo.treinar_autoencoder(epocas=300, salvar=True,nome_da_base='Kyoto',  batch_size=8)\n",
    "\n",
    "    del AutoencoderModelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
