{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentandoDatasets import segmentando_datasets\n",
    "segmentando_datasets(10000,10000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessamento import *\n",
    "\n",
    "csv_file = 'Datasets_csv/df_PUC.csv'\n",
    "train, teste, val, _, _, _ = preprocessamento(csv_file, 0.6, 0.2, 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho da entrada\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "# Camadas do encoder\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Camadas do decoder\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Definir o modelo\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = 'weights_parciais/weights-improvement-{epoch:02d}-{loss:.2f}.weights.h5'\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                  save_weights_only=True, \n",
    "                                  monitor='loss',\n",
    "                                  mode='max', \n",
    "                                  save_best_only=True, \n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "history = autoencoder.fit(train,\n",
    "                epochs=10,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                callbacks=[cp_callback],\n",
    "                validation_data=(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Modelos_keras/Autoencoder.keras\")\n",
    "autoencoder.save_weights(\"weights_finais/Autoencoder.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(\"weights_finais/Autoencoder.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "decoder = Model(encoded, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_original_and_reconstructed(model, X_val, num_images=5):\n",
    "    \"\"\"\n",
    "    Plota as imagens originais e suas versões reconstruídas pelo autoencoder.\n",
    "    \n",
    "    Parâmetros:\n",
    "        model (keras.Model): O modelo do autoencoder treinado.\n",
    "        X_val (numpy.ndarray): Conjunto de dados de validação.\n",
    "        num_images (int): Número de imagens a serem plotadas.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Seleciona uma imagem aleatória do conjunto de validação\n",
    "        image_index = np.random.randint(0, len(X_val))\n",
    "        original_image = X_val[image_index]\n",
    "\n",
    "        # Passa a imagem original pelo autoencoder para obter a imagem reconstruída\n",
    "        reconstructed_image = model.predict(original_image.reshape(1, 256, 256, 3))[0]\n",
    "\n",
    "        # Plota a imagem original e a reconstruída\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(original_image)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1 + num_images)\n",
    "        plt.imshow(reconstructed_image)\n",
    "        plt.title(\"Reconstruída\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, _ = next(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_original_and_reconstructed(autoencoder, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessamento import preprocessamento_dataframe_unico\n",
    "\n",
    "UFPR04, _ = preprocessamento_dataframe_unico(\"Datasets_csv/df_UFPR04.csv\", True)\n",
    "UFPR05, _ = preprocessamento_dataframe_unico(\"Datasets_csv/df_UFPR05.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_UFPR04,_ = next(UFPR04)\n",
    "X_UFPR05,_ = next(UFPR05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_original_and_reconstructed(autoencoder, X_UFPR04)\n",
    "plot_original_and_reconstructed(autoencoder, X_UFPR05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=input_img, outputs=encoded)\n",
    "\n",
    "# Congelando as camadas do encoder para classificação\n",
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
